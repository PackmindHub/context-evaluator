Implement the following plan:

# Plan: Add LLM-Generated Bloat Detection to Evaluator 10

## Context

AGENTS.md files are most often generated by LLMs and agents themselves. This means they frequently contain verbose padding, boilerplate preambles, unnecessary justifications, and obvious-for-AI explanations that waste context window tokens. Currently, no evaluator specifically targets these phrase-level bloat patterns. The goal is to detect obvious, clear-cut cases without being too aggressive.

## Approach: New Section 10.4 in `completeness.md`

Add a single new section **10.4 - LLM-Generated Verbal Bloat** to `prompts/evaluators/completeness.md`. This fits naturally alongside the existing content balance axis (10.1 too short, 10.2 too verbose/tutorial, 10.3 wrong placement, 10.4 inflated prose).

### Boundary with Existing Sections

| Existing | New 10.4 |
|---|---|
| **10.2** - Structural over-documentation (500-line Node.js tutorial, teaching basic concepts) | **10.4** - Phrase-level noise (padding wrappers, preambles, tool definitions) |
| **01.2** - Vague instructions that are non-actionable ("follow best practices") | **10.4** - Verbose-but-clear instructions that could be 80% shorter |
| **06.2** - Imperatives without specificity ("never do X" with no alternative) | **10.4** - Clear instructions wrapped in unnecessary filler words |

### Five Detection Patterns

**A. Document-Level Boilerplate Preambles** - "This document provides comprehensive guidance...", "The following sections outline..."
- Bad: `This document provides comprehensive guidance to AI coding agents working on this codebase.` then `## Setup` with `npm install`
- Good: Just `## Setup` with `npm install`

**B. Verbose Padding Phrases** - "It is important to note that...", "Please ensure that you always...", "Developers should be aware that..."
- Bad: `It is important to note that you must run npm run lint before committing`
- Good: `Run npm run lint before committing`

**C. Unnecessary Justifications** - History/rationale paragraphs explaining WHY a rule exists when agents just need WHAT to do
- Bad: `We use ESLint because it helps maintain code quality and catches bugs early. It was adopted in 2021 after several production issues...`
- Good: `ESLint config: .eslintrc.json. Run: npm run lint`
- Exception: Brief 1-sentence "why" for non-obvious behavior is OK

**D. Stating the Obvious for AI Agents** - Wikipedia-style definitions of well-known tools (Git, npm, Jest, Docker, etc.)
- Bad: `Git is a distributed version control system that tracks changes in files...`
- Good: Just provide the git workflow commands
- Exception: Proprietary/internal tools DO need explanations

**E. Intra-File Concept Repetition** - Same instruction rephrased in 3+ sections within one file
- Bad: Lint requirement stated in Quick Start, Development Workflow, AND Code Quality sections
- Good: Single mention in the most prominent location

### Severity Thresholds (Conservative)

| Score | Description |
|---|---|
| 8-9 | Multiple patterns pervasive throughout file |
| 7 | One pattern clearly pervasive (>10 instances) or two patterns appear repeatedly |
| 6 | One pattern in moderate but notable way (5-10 instances) |
| â‰¤5 | DO NOT REPORT |

**Key calibration**: Report ONE consolidated issue per file bundling all instances. Minimum ~5 phrase-level instances or 3+ sections affected before reporting.

## Changes Required

### 1. `prompts/evaluators/completeness.md`
- **Insert** new section 10.4 after section 10.3 (before "Content Quality Indicators" section at ~line 192)
- Content: Full section with detection signals, 5 patterns (A-E) with examples, severity guidelines, cross-evaluator scope notes, and explicit DO NOT flag lists
- **Update** line 555: change `(patterns 10.1-10.2 above)` to `(patterns 10.1-10.4 above)`

### 2. `CLAUDE.md` (evaluator coverage documentation)
- Add entry for new section under evaluator 10: `10.4 - LLM-Generated Verbal Bloat`

### No TypeScript Changes Needed
- `evaluator-types.ts` already has `completeness.md` configured as `error` type
- Section numbering is only in JSON output from the LLM, not in routing/filtering logic
- No new evaluator file = no config changes

## Verification

1. Run `bun run test` to ensure no regressions
2. Run `bun run lint` to ensure formatting is clean
3. Test manually by running an evaluation against a known verbose AGENTS.md file to verify the evaluator picks up 10.4 patterns


If you need specific details from before exiting plan mode (like exact code snippets, error messages, or content you generated), read the full transcript at: /Users/cedricteyton/.REDACTED.jsonl

---

comit